{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anomaly.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSaber9/Thesis2021/blob/main/anomaly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAQsVY7-gWmo"
      },
      "source": [
        "pip install lime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWjs_e6aKbHy"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "from glob import iglob\n",
        "import numpy as np\n",
        "import time\n",
        "from keras.utils import plot_model\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import recall_score, accuracy_score, precision_score, confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import lime\n",
        "import lime.lime_tabular"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVaAFqXy1N-G"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QiBMDmB7iJc"
      },
      "source": [
        "Loading Benign Traffic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2faLMX8KbIj"
      },
      "source": [
        "print(\"Loading training data...\")\n",
        "#df = pd.concat((pd.read_csv(f) for f in iglob('../data/**/benign_traffic.csv', recursive=True)), ignore_index=True)\n",
        "df = pd.concat((pd.read_csv(f) for f in iglob('/content/drive/My Drive/Colab Notebooks/DataIoT/*.benign.csv' , recursive= True)), ignore_index=True)\n",
        "\n",
        "print (\"Done ..\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov90Sh2KKbIo"
      },
      "source": [
        "x_train, x_opt, x_test = np.split(df.sample(frac=1, random_state=17), [int(1/3*len(df)), int(2/3*len(df))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPaFYwKA7d59"
      },
      "source": [
        "Loading Mirai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jJg-R_rKbIq"
      },
      "source": [
        "#df_mirai = pd.concat((pd.read_csv(f) for f in iglob('../data/**/mirai_attacks/*.csv', recursive=True)), ignore_index=True)\n",
        "df_mirai = pd.concat((pd.read_csv(f) for f in iglob('/content/drive/My Drive/Colab Notebooks/DataIoT/*.mirai.*.csv' , recursive= True)), ignore_index=True)\n",
        "\n",
        "print (\"Done ..\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqN_HQS57s87"
      },
      "source": [
        "Loading Gafgyt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_WrM_BiKbIu"
      },
      "source": [
        "#df_gafgyt = pd.concat((pd.read_csv(f) for f in iglob('../data/**/gafgyt_attacks/*.csv', recursive=True)), ignore_index=True)\n",
        "df_gafgyt = pd.concat((pd.read_csv(f) for f in iglob('/content/drive/My Drive/Colab Notebooks/DataIoT/*.gafgyt.*.csv' , recursive= True)), ignore_index=True)\n",
        "\n",
        "print (\"Done ..\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IstLwoy670I1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo89ouaoKbIv"
      },
      "source": [
        "df_attack = df_mirai.append(df_gafgyt)\n",
        "df_attack['class'] = 'attack'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4eu4wAVKbIx"
      },
      "source": [
        "df_fish = x_train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsuKvjTsKbIy"
      },
      "source": [
        "df_fish['class'] = 'benign'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeUDaH-6KbIz"
      },
      "source": [
        "df_fish = df_fish.append(df_attack.sample(n=df_fish.shape[0], random_state=17))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEeJ8Du7KbI1"
      },
      "source": [
        "plot_n = 2000\n",
        "atk = df_attack.sample(n=plot_n, random_state=76)\n",
        "nrm = x_train.sample(n=plot_n, random_state=42)\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.scatter(nrm['MI_dir_L0.1_weight'],nrm['MI_dir_L1_weight'],10,c='blue', label='normal',alpha=0.5)\n",
        "ax1.scatter(atk['MI_dir_L0.1_weight'],atk['MI_dir_L1_weight'],10,c='red',label='attack',alpha=0.5)\n",
        "\n",
        "plt.xlabel('MI_dir_L0.1_weight')\n",
        "plt.ylabel('MI_dir_L1_weight')\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLyKHXk0KbI2"
      },
      "source": [
        "classes = ['benign', 'attack']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ViwTmXiKbI4"
      },
      "source": [
        "scored = []\n",
        "indices = {}\n",
        "shps = {}\n",
        "for cl in classes:\n",
        "    indices[cl] = df_fish['class'] == cl\n",
        "    shps[cl] =  df_fish[indices[cl]].shape[0]\n",
        "        \n",
        "for col in df_fish.columns:\n",
        "    if col == 'class':\n",
        "        continue\n",
        "    num = 0\n",
        "    den = 0\n",
        "    m = df_fish[col].mean()\n",
        "    \n",
        "    for cl in classes:\n",
        "        num += (shps[cl] / df_fish.shape[0]) * (m - df_fish[indices[cl]][col].mean())**2\n",
        "        den += (shps[cl] / df_fish.shape[0]) * df_fish[indices[cl]][col].var()\n",
        "    score = {'feature': col, 'score': num / den}\n",
        "    scored.append(score)\n",
        "    #print(score)\n",
        "scored.sort(key=lambda x: x['score'], reverse=True)\n",
        "scored[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXDVHu_IKbI9"
      },
      "source": [
        "with open('anomaly_scores.csv', 'w+') as file:\n",
        "    lines = ['Feature,Score\\n']\n",
        "    for s in scored:\n",
        "        lines.append(s['feature'] + ',' + \"{0:.2f}\".format(s['score']) + '\\n')\n",
        "    file.writelines(lines)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHaihNtYKbJA"
      },
      "source": [
        "def create_model(input_dim):\n",
        "    inp = Input(shape=(input_dim,))\n",
        "    encoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(inp)\n",
        "    encoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
        "    encoder = Dense(int(math.ceil(0.25 * input_dim)), activation=\"tanh\")(encoder)\n",
        "    decoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
        "    decoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(decoder)\n",
        "    decoder = Dense(input_dim)(decoder)\n",
        "    return Model(inp, decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmXyYY6tKbJD"
      },
      "source": [
        "class AnomalyModel:\n",
        "    def __init__(self, model, threshold, scaler):\n",
        "        self.model = model\n",
        "        self.threshold = threshold\n",
        "        self.scaler = scaler\n",
        "\n",
        "    def predict(self, x):\n",
        "        x_pred = self.model.predict(x)\n",
        "        mse = np.mean(np.power(x - x_pred, 2), axis=1)\n",
        "        y_pred = mse > self.threshold\n",
        "        return y_pred.astype(int)\n",
        "\n",
        "    def scale_predict_classes(self, x):\n",
        "        x = self.scaler.transform(x)\n",
        "        y_pred = self.predict(x)\n",
        "        classes_arr = []\n",
        "        for e in y_pred:\n",
        "            el = [0,0]\n",
        "            el[e] = 1\n",
        "            classes_arr.append(el)\n",
        "\n",
        "        return np.array(classes_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rySUQ5zlKbJG"
      },
      "source": [
        "for top_n_features in [115]:\n",
        "    fs = [it['feature'] for it in scored[:top_n_features]]\n",
        "    X_train = x_train[fs]\n",
        "    X_opt = x_opt[fs]\n",
        "    X_test = x_test[fs]\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_opt = scaler.transform(X_opt)\n",
        "    \n",
        "    model = create_model(top_n_features)\n",
        "    model.compile(loss=\"mean_squared_error\",\n",
        "                    optimizer=\"adam\")\n",
        "    cp = ModelCheckpoint(filepath=f\"anomaly/anomaly{top_n_features}.h5\",\n",
        "                                 monitor='val_loss',\n",
        "                               save_best_only=True,\n",
        "                               verbose=0)\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    start = time.time()\n",
        "    epochs = 100\n",
        "    history = model.fit(X_train, X_train,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(X_opt, X_opt),\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp, es])\n",
        "    \n",
        "    end = time.time()\n",
        "    print('time')\n",
        "    print(end - start)\n",
        "    print(model.summary())\n",
        "    \n",
        "    x_opt_predictions = model.predict(X_opt)\n",
        "    mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
        "    mean = mse.mean()\n",
        "    std = mse.std()\n",
        "    \n",
        "    \n",
        "    df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
        "    df_benign['malicious'] = 0\n",
        "    df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
        "    df_malicious['malicious'] = 1\n",
        "    df2 = df_benign.append(df_malicious)\n",
        "    X_opt = df2.drop(columns=['malicious']).values\n",
        "    X_opt_scaled = scaler.transform(X_opt)\n",
        "    \n",
        "    Y_opt = df2['malicious']\n",
        "    best_acc = 0\n",
        "    best_n = 0\n",
        "    print('Selecting n------------------')\n",
        "    for n in range(1,11):\n",
        "        tr = mean + n * std\n",
        "        m = AnomalyModel(model , tr, scaler)\n",
        "        Y_pred = m.predict(X_opt_scaled)\n",
        "        print(f'For n {n}')\n",
        "        print('Accuracy')\n",
        "        acc = accuracy_score(Y_opt, Y_pred)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_n = n\n",
        "        print(acc)\n",
        "        print('Precision')\n",
        "        print(precision_score(Y_opt, Y_pred))\n",
        "        print('CM')\n",
        "        print(confusion_matrix(Y_opt, Y_pred))\n",
        "        #accs.append({'acc': acc, 'n': top_n_features, 'cm': confusion_matrix(Y_test, Y_pred)})\n",
        "        \n",
        "    df_benign = pd.DataFrame(X_test, columns=fs)\n",
        "    df_benign['malicious'] = 0\n",
        "    df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
        "    df_malicious['malicious'] = 1\n",
        "    df2 = df_benign.append(df_malicious)\n",
        "    X_test = df2.drop(columns=['malicious']).values\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    Y_test = df2['malicious']\n",
        "    \n",
        "    tr = mean + best_n * std\n",
        "    m = AnomalyModel(model , tr, scaler)\n",
        "    Y_pred = m.predict(X_test_scaled)\n",
        "    print('Test-----------------')\n",
        "    print(f'best n {best_n}')\n",
        "    print('Accuracy')\n",
        "    acc = accuracy_score(Y_test, Y_pred)\n",
        "    print(acc)\n",
        "    print('Precision')\n",
        "    print(precision_score(Y_test, Y_pred))\n",
        "    print('CM')\n",
        "    cm = confusion_matrix(Y_test, Y_pred)\n",
        "    print(cm)   \n",
        "#print(accs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eMJcLP0KbJP"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Opt'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffxvtNRSZnVQ"
      },
      "source": [
        "#cm = confusion_matrix(Y_test, Y_pred)\n",
        "#classes = ['benign', 'attack']\n",
        "#plot_confusion_matrix(cm, classes, title='Attack detection')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YMyTO-RmdU1"
      },
      "source": [
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX7YXZKpk3U1"
      },
      "source": [
        "# Creating the confusion matrix graphs\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d',cmap=plt.cm.Blues, xticklabels=['begin', 'attack'], yticklabels=['begin', 'attack'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dXGVb-tk3AA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3sQf2_urKVc"
      },
      "source": [
        "acs = []\n",
        "params_num = []\n",
        "best_n = 10\n",
        "for top_n_features in [3,5,10,20,30,40,50,60,70,80,90,100,115]:\n",
        "    print(\"N \" + str(top_n_features))\n",
        "    fs = [it['feature'] for it in scored[:top_n_features]]\n",
        "    X_train = x_train[fs]\n",
        "    X_opt = x_opt[fs]\n",
        "    X_test = x_test[fs]\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_opt = scaler.transform(X_opt)\n",
        "    cp = ModelCheckpoint(monitor='val_loss',\n",
        "                               save_best_only=True,\n",
        "                               verbose=0, filepath='temp')\n",
        "    \n",
        "    model = create_model(top_n_features)\n",
        "    model.compile(loss=\"mean_squared_error\",\n",
        "                    optimizer=\"adam\")\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
        "    model.fit(X_train, X_train,\n",
        "                    epochs=50,\n",
        "                    validation_data=(X_opt, X_opt),\n",
        "                    verbose=1, callbacks=[es, cp])\n",
        "    \n",
        "    \n",
        "    x_opt_predictions = model.predict(X_opt)\n",
        "    mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
        "    mean = mse.mean()\n",
        "    std = mse.std()\n",
        "    \n",
        "        \n",
        "    df_benign = pd.DataFrame(X_test, columns=fs)\n",
        "    df_benign['malicious'] = 0\n",
        "    df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
        "    df_malicious['malicious'] = 1\n",
        "    df2 = df_benign.append(df_malicious)\n",
        "    X_test = df2.drop(columns=['malicious']).values\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    Y_test = df2['malicious']\n",
        "    \n",
        "    tr = mean + best_n * std\n",
        "    m = AnomalyModel(model , tr, scaler)\n",
        "    Y_pred = m.predict(X_test_scaled)\n",
        "    print('Test-----------------')\n",
        "    print('Accuracy')\n",
        "    acc = accuracy_score(Y_test, Y_pred)\n",
        "    print(acc)\n",
        "    acs.append(acc)\n",
        "    params_num.append(model.count_params())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKPMQE8eKbJY"
      },
      "source": [
        "acs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML8rjXBkKbJV"
      },
      "source": [
        "plt.xlabel('Features')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "#plt.ylim(bottom=0.995)\n",
        "\n",
        "\n",
        "plt.xticks([3,10,20,30,40,50,60,70,80,90,100,115])\n",
        "plt.plot([3,5,10,20,30,40,50,60,70,80,90,100,115], acs)\n",
        "\n",
        "plt.title(\" matplotlib accuracy with feathers\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVGqi9lBKbJZ"
      },
      "source": [
        "#model = load_model('anomaly/anomaly115.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-2418UfKbJb"
      },
      "source": [
        "#plot_model(model, to_file='model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXVnpGKzKbJc"
      },
      "source": [
        "explainer = lime.lime_tabular.LimeTabularExplainer(X_test, feature_names=fs, class_names=classes, discretize_continuous=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPVqcgHVKbJf"
      },
      "source": [
        "test = df_attack.sample(n=1, random_state=47)[fs].values\n",
        "\n",
        "exp = explainer.explain_instance(test[0], m.scale_predict_classes, num_features=5)\n",
        "exp.show_in_notebook(show_table=True, show_all=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIWGNhXyKbJh"
      },
      "source": [
        "m.scale_predict_classes(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4a9ovRQKbJh"
      },
      "source": [
        "exp.as_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XMVCwiIKbJi"
      },
      "source": [
        "\",\".join([\"{0:.2f}\".format(s) for s in test[0]])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}